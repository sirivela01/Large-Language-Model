# Install dependencies
!pip install -q transformers torch

from transformers import BertTokenizer, BertForSequenceClassification
import torch

# Load pretrained tokenizer and model
tokenizer = BertTokenizer.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")
model = BertForSequenceClassification.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")

# Prediction function
def predict_sentiment(text):
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True)
    with torch.no_grad():
        outputs = model(**inputs)
    predicted_class = torch.argmax(outputs.logits, dim=1).item()
    sentiment = ["Very Negative", "Negative", "Neutral", "Positive", "Very Positive"]
    return sentiment[predicted_class]

# Test samples
texts = [
    "I love this product!",
    "The movie was average",
    "Worst experience ever"
]

for t in texts:
    print(f"{t} --> {predict_sentiment(t)}")
